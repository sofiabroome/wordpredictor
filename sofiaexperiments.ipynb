{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments for n-grams without smoothing or grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'austen-emma.txt',\n",
       " u'austen-persuasion.txt',\n",
       " u'austen-sense.txt',\n",
       " u'bible-kjv.txt',\n",
       " u'blake-poems.txt',\n",
       " u'bryant-stories.txt',\n",
       " u'burgess-busterbrown.txt',\n",
       " u'carroll-alice.txt',\n",
       " u'chesterton-ball.txt',\n",
       " u'chesterton-brown.txt',\n",
       " u'chesterton-thursday.txt',\n",
       " u'edgeworth-parents.txt',\n",
       " u'melville-moby_dick.txt',\n",
       " u'milton-paradise.txt',\n",
       " u'shakespeare-caesar.txt',\n",
       " u'shakespeare-hamlet.txt',\n",
       " u'shakespeare-macbeth.txt',\n",
       " u'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.bigram_model import BigramModel\n",
    "from models.trigram_model import TrigramModel\n",
    "from models.ngram_model import NgramModel\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_corpora(corpora, query, n):\n",
    "    for k in range(2, 5, 1):\n",
    "        fm = NgramModel(k)\n",
    "        fm.train(corpora)\n",
    "        print \"Result for a\",(str(k)+\"-gram: \"),fm.predict_words(query, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010654 154883 8354\n"
     ]
    }
   ],
   "source": [
    "t1 = gutenberg.words('bible-kjv.txt');\n",
    "t2 = gutenberg.words('whitman-leaves.txt');\n",
    "t3 = gutenberg.words('blake-poems.txt');\n",
    "print len(t1), len(t2), len(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(2, 5, 1):\n",
    "    fm1 = NgramModel(k)\n",
    "    fm1.train(t1)\n",
    "    print \"Testing with the bible (very large corpus)\"\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm1.predict_words(\"I am afraid they\", 10)\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(2, 5, 1):\n",
    "    fm2 = NgramModel(k)\n",
    "    fm2.train(t2)\n",
    "    print \"Testing with the poetry collection Leaves of Grass, medium large (154883 words)\"\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm2.predict_words(\"I am afraid they\", 10)\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with Blake poems, small corpus (8354 words)\n",
      "Results for a 2-gram: \n",
      "I am afraid they sleep ? \" Ona , As Tom , The cloud\n",
      "I am afraid they cry of every face Is this tree . Then we\n",
      "I am afraid they need not , Merrily , They visit caves the Parson\n",
      "I am afraid they should Thel answerd , And forget his priest and wept\n",
      "I am afraid they know . And her seat , Know that it '\n",
      "\n",
      "\n",
      "\n",
      "Testing with Blake poems, small corpus (8354 words)\n",
      "Results for a 3-gram: \n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "I am afraid they\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "I am afraid they\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "I am afraid they\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "I am afraid they\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "I am afraid they\n",
      "\n",
      "\n",
      "\n",
      "Testing with Blake poems, small corpus (8354 words)\n",
      "Results for a 4-gram: \n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "I am afraid they\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "I am afraid they\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "I am afraid they\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "I am afraid they\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "I am afraid they\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(2, 5, 1):\n",
    "    fm3 = NgramModel(k)\n",
    "    fm3.train(t3)\n",
    "    print \"Testing with Blake poems, small corpus (8354 words)\"\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm3.predict_words(\"I am afraid they\", 10)\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
