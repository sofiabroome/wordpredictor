{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260819\n",
      "34110\n"
     ]
    }
   ],
   "source": [
    "from models.bigram_model import BigramModel\n",
    "from models.trigram_model import TrigramModel\n",
    "from models.ngram_model import NgramModel\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "melville = gutenberg.words('melville-moby_dick.txt')\n",
    "carroll = gutenberg.words('carroll-alice.txt')\n",
    "print len(melville)\n",
    "print len(carroll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'austen-emma.txt',\n",
       " u'austen-persuasion.txt',\n",
       " u'austen-sense.txt',\n",
       " u'bible-kjv.txt',\n",
       " u'blake-poems.txt',\n",
       " u'bryant-stories.txt',\n",
       " u'burgess-busterbrown.txt',\n",
       " u'carroll-alice.txt',\n",
       " u'chesterton-ball.txt',\n",
       " u'chesterton-brown.txt',\n",
       " u'chesterton-thursday.txt',\n",
       " u'edgeworth-parents.txt',\n",
       " u'melville-moby_dick.txt',\n",
       " u'milton-paradise.txt',\n",
       " u'shakespeare-caesar.txt',\n",
       " u'shakespeare-hamlet.txt',\n",
       " u'shakespeare-macbeth.txt',\n",
       " u'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'I think that you really perceived drops of moisture in the spout , whether'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm = NgramModel(4)\n",
    "fm.train(words)\n",
    "\n",
    "fm.predict_words(\"I think that you\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_corpora(corpora, query, n):\n",
    "    for k in range(2, 5, 1):\n",
    "        fm = NgramModel(k)\n",
    "        fm.train(corpora)\n",
    "        print \"Result for a\",(str(k)+\"-gram: \"),fm.predict_words(query, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  Alice was looking for a very neatly spread his belt and began . '\n",
      "Result for a  3-gram:  Alice was looking for eggs , I can kick a little bottle that stood\n",
      "Result for a  4-gram:  Alice was looking for the fan and a pair of white kid gloves ,\n"
     ]
    }
   ],
   "source": [
    "test_corpora(carroll, \"Alice was looking for\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  However , there is a whale - fleet of this , and the two\n",
      "Result for a  3-gram:  However , there is no place to live in the captain ' s a\n",
      "Result for a  4-gram:  However , there is no telling . But a day or two previous ,\n"
     ]
    }
   ],
   "source": [
    "test_corpora(melville, \"However , there is\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  I think that you must have been offered a whale , when the long\n",
      "Result for a  3-gram:  I think that you do yours in approved state stocks bringing in good time\n",
      "Result for a  4-gram:  I think that you really perceived drops of moisture in the spout - hole\n"
     ]
    }
   ],
   "source": [
    "test_corpora(melville, \"I think that you\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25833 37360 23140\n"
     ]
    }
   ],
   "source": [
    "s1 = gutenberg.words('shakespeare-caesar.txt');\n",
    "s2 = gutenberg.words('shakespeare-hamlet.txt');\n",
    "s3 = gutenberg.words('shakespeare-macbeth.txt');\n",
    "print len(s1), len(s2), len(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  You are in great Caesar , and for your Testie Humour ? And do you are at Philippi Bru . I know not Brutus , I am no man , and friendly Conference ,\n",
      "Result for a  3-gram:  You are in great Caesars eare , For if thou louest me , Ile ne ' re look ' d , And tell them , it is not the Face of men , and\n",
      "Result for a  4-gram:  You are in great danger , I recouer them . As proper men as euer trod vpon Neats Leather , haue gone vpon my handy - worke Fla . But wherefore did you so\n"
     ]
    }
   ],
   "source": [
    "test_corpora(s1, \"You are in great\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  This great buyer of the King . I could be so , That I am very potent poyson in this ; Addicted so ,\n",
      "Result for a  3-gram:  This great buyer of Land , And so am I ? Is it your owne necke downe Qu . Alas then , my Lord\n",
      "Result for a  4-gram:  This great buyer of Land , with his Statutes , his Recognizances , his Fines , and the trifling of his fauours , Hold\n"
     ]
    }
   ],
   "source": [
    "test_corpora(s2, \"This great buyer of\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  I am afraid they not be done to thine owne demerits , That most may you haue tied me , and trouble , And\n",
      "Result for a  3-gram:  I am afraid they haue more vices then it had before , to thinke what I doe , and the Ague eate them vp\n",
      "Result for a  4-gram:  I am afraid they haue awak ' d him well , He hath a Wisdome , that doth guide his Valour , To act\n"
     ]
    }
   ],
   "source": [
    "test_corpora(s3, \"I am afraid they\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIRST EXPERIMENTS : TUNING N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for a 1-gram: \n",
      "Sum probs =  0\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "Alice was looking for\n",
      "Sum probs =  0\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "Alice was looking for\n",
      "Sum probs =  0\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "Alice was looking for\n",
      "Sum probs =  0\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "Alice was looking for\n",
      "Sum probs =  0\n",
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "Alice was looking for\n",
      "\n",
      "\n",
      "Results for a 2-gram: \n",
      "Sum probs =  0.00410448855141\n",
      "Sum probs =  0.00331290861649\n",
      "Sum probs =  0.00378199302237\n",
      "Sum probs =  0.00507197513853\n",
      "Sum probs =  0.0159195520244\n",
      "Sum probs =  0.0103198569293\n",
      "Sum probs =  0.000791579934915\n",
      "Sum probs =  0.0180304318508\n",
      "Sum probs =  0.00369403969627\n",
      "Sum probs =  8.79533261016e-05\n",
      "Alice was looking for this they all I was going a very dull reality\n",
      "Sum probs =  0.00410448855141\n",
      "Sum probs =  0.0154504676185\n",
      "Sum probs =  0.000879533261016\n",
      "Sum probs =  0.0034008619426\n",
      "Sum probs =  0.00712421941423\n",
      "Sum probs =  0.000557037731977\n",
      "Sum probs =  0.0584303263068\n",
      "Sum probs =  0.0159195520244\n",
      "Sum probs =  0.00128998211616\n",
      "Sum probs =  0.0034008619426\n",
      "Alice was looking for it made out her feet , I get out into\n",
      "Sum probs =  0.00410448855141\n",
      "Sum probs =  0.000146588876836\n",
      "Sum probs =  5.86355507344e-05\n",
      "Sum probs =  8.79533261016e-05\n",
      "Sum probs =  0.000791579934915\n",
      "Sum probs =  0.00199360872497\n",
      "Sum probs =  0.0584303263068\n",
      "Sum probs =  0.0159195520244\n",
      "Sum probs =  0.00149520654373\n",
      "Sum probs =  0.0507490691606\n",
      "Alice was looking for asking riddles .-- How do , I don ' m\n",
      "Sum probs =  0.00410448855141\n",
      "Sum probs =  0.00140725321763\n",
      "Sum probs =  0.00117271101469\n",
      "Sum probs =  8.79533261016e-05\n",
      "Sum probs =  0.0584303263068\n",
      "Sum probs =  0.00721217274033\n",
      "Sum probs =  0.0149227476619\n",
      "Sum probs =  0.000879533261016\n",
      "Sum probs =  0.0154504676185\n",
      "Sum probs =  5.86355507344e-05\n",
      "Alice was looking for some other paw , as she heard it watched the\n",
      "Sum probs =  0.00410448855141\n",
      "Sum probs =  0.0159195520244\n",
      "Sum probs =  0.00149520654373\n",
      "Sum probs =  0.0507490691606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3a92e74fa334>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Results for a\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"-gram: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;32mprint\u001b[0m \u001b[0mfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Alice was looking for\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/krebs/Documents/Artifial_Intelligence/Project/wordpredictor/models/ngram_model.py\u001b[0m in \u001b[0;36mpredict_words\u001b[1;34m(self, base_query_string, n)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_query_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_next_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_query_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mprob_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/krebs/Documents/Artifial_Intelligence/Project/wordpredictor/models/ngram_model.py\u001b[0m in \u001b[0;36mpredict_next_word\u001b[1;34m(self, base_query_string)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mngram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobs_ng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/probability.pyc\u001b[0m in \u001b[0;36mprob\u001b[1;34m(self, sample)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_freqdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/probability.pyc\u001b[0m in \u001b[0;36mfreq\u001b[1;34m(self, sample)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/probability.pyc\u001b[0m in \u001b[0;36mN\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \"\"\"\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in range(1, 5, 1):\n",
    "    fm = NgramModel(k)\n",
    "    fm.train(carroll)\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm.predict_words(\"Alice was looking for\", 10)\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(2, 5, 1):\n",
    "    fm = NgramModel(k)\n",
    "    fm.train(s3)\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm.predict_words(\"I am afraid they\", 10)\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOOTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "That was Alice who\n",
      "3016\n"
     ]
    }
   ],
   "source": [
    "fm = NgramModel(5);\n",
    "fm.train(carroll);\n",
    "print fm.predict_words(\"That was Alice who\", 5)\n",
    "print len(fm.unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fm.smooth(\"LidstoneProbDist\", fm.frequencies, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'IN'), 0.000331564986737383]\n",
      "Winning match is:  [(u'was', u'Alice', u'who', u'IN', u'tucked'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Alice', u'who', u'IN', u'tucked', u'almost'), 0.000331564986737383]\n",
      "Winning match is:  [(u'who', u'IN', u'tucked', u'almost', u'twinkling'), 0.000331564986737383]\n",
      "Winning match is:  [(u'IN', u'tucked', u'almost', u'twinkling', u'might'), 0.000331564986737383]\n",
      "Winning match is:  [(u'tucked', u'almost', u'twinkling', u'might', u'fair'), 0.000331564986737383]\n",
      "Winning match is:  [(u'almost', u'twinkling', u'might', u'fair', u'label'), 0.000331564986737383]\n",
      "Winning match is:  [(u'twinkling', u'might', u'fair', u'label', u'friend'), 0.000331564986737383]\n",
      "Winning match is:  [(u'might', u'fair', u'label', u'friend', u'lying'), 0.000331564986737383]\n",
      "Winning match is:  [(u'fair', u'label', u'friend', u'lying', u'measure'), 0.000331564986737383]\n",
      "That was Alice who IN tucked almost twinkling might fair label friend lying measure\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'received'), 0.000331564986737383]\n",
      "Winning match is:  [(u'was', u'Alice', u'who', u'received', u'screaming'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Alice', u'who', u'received', u'screaming', u'bad'), 0.000331564986737383]\n",
      "Winning match is:  [(u'who', u'received', u'screaming', u'bad', u'manage'), 0.000331564986737383]\n",
      "Winning match is:  [(u'received', u'screaming', u'bad', u'manage', u'laughter'), 0.000331564986737383]\n",
      "Winning match is:  [(u'screaming', u'bad', u'manage', u'laughter', u'bringing'), 0.000331564986737383]\n",
      "Winning match is:  [(u'bad', u'manage', u'laughter', u'bringing', u'drawing'), 0.000331564986737383]\n",
      "Winning match is:  [(u'manage', u'laughter', u'bringing', u'drawing', u'nose'), 0.000331564986737383]\n",
      "Winning match is:  [(u'laughter', u'bringing', u'drawing', u'nose', u'vegetable'), 0.000331564986737383]\n",
      "Winning match is:  [(u'bringing', u'drawing', u'nose', u'vegetable', u'executes'), 0.000331564986737383]\n",
      "That was Alice who received screaming bad manage laughter bringing drawing nose vegetable executes\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'C'), 0.000331564986737383]\n",
      "Winning match is:  [(u'was', u'Alice', u'who', u'C', u'hint'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Alice', u'who', u'C', u'hint', u'Fifteenth'), 0.000331564986737383]\n",
      "Winning match is:  [(u'who', u'C', u'hint', u'Fifteenth', u'grow'), 0.000331564986737383]\n",
      "Winning match is:  [(u'C', u'hint', u'Fifteenth', u'grow', u'imagine'), 0.000331564986737383]\n",
      "Winning match is:  [(u'hint', u'Fifteenth', u'grow', u'imagine', u'chorus'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Fifteenth', u'grow', u'imagine', u'chorus', u\"',\"), 0.000331564986737383]\n",
      "Winning match is:  [(u'grow', u'imagine', u'chorus', u\"',\", u'children'), 0.000331564986737383]\n",
      "Winning match is:  [(u'imagine', u'chorus', u\"',\", u'children', u'remarks'), 0.000331564986737383]\n",
      "Winning match is:  [(u'chorus', u\"',\", u'children', u'remarks', u'quick'), 0.000331564986737383]\n",
      "That was Alice who C hint Fifteenth grow imagine chorus ', children remarks quick\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'subject'), 0.000331564986737383]\n",
      "Winning match is:  [(u'was', u'Alice', u'who', u'subject', u'sides'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Alice', u'who', u'subject', u'sides', u'emphasis'), 0.000331564986737383]\n",
      "Winning match is:  [(u'who', u'subject', u'sides', u'emphasis', u'supple'), 0.000331564986737383]\n",
      "Winning match is:  [(u'subject', u'sides', u'emphasis', u'supple', u'standing'), 0.000331564986737383]\n",
      "Winning match is:  [(u'sides', u'emphasis', u'supple', u'standing', u'sign'), 0.000331564986737383]\n",
      "Winning match is:  [(u'emphasis', u'supple', u'standing', u'sign', u'severely'), 0.000331564986737383]\n",
      "Winning match is:  [(u'supple', u'standing', u'sign', u'severely', u'introduced'), 0.000331564986737383]\n",
      "Winning match is:  [(u'standing', u'sign', u'severely', u'introduced', u'THERE'), 0.000331564986737383]\n",
      "Winning match is:  [(u'sign', u'severely', u'introduced', u'THERE', u'):--'), 0.000331564986737383]\n",
      "That was Alice who subject sides emphasis supple standing sign severely introduced THERE ):--\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'kept'), 0.000331564986737383]\n",
      "Winning match is:  [(u'was', u'Alice', u'who', u'kept', u'may'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Alice', u'who', u'kept', u'may', u'king'), 0.000331564986737383]\n",
      "Winning match is:  [(u'who', u'kept', u'may', u'king', u'murdering'), 0.000331564986737383]\n",
      "Winning match is:  [(u'kept', u'may', u'king', u'murdering', u'harm'), 0.000331564986737383]\n",
      "Winning match is:  [(u'may', u'king', u'murdering', u'harm', u'persisted'), 0.000331564986737383]\n",
      "Winning match is:  [(u'king', u'murdering', u'harm', u'persisted', u'cats'), 0.000331564986737383]\n",
      "Winning match is:  [(u'murdering', u'harm', u'persisted', u'cats', u'harm'), 0.000331564986737383]\n",
      "Winning match is:  [(u'harm', u'persisted', u'cats', u'harm', u'Twenty'), 0.000331564986737383]\n",
      "Winning match is:  [(u'persisted', u'cats', u'harm', u'Twenty', u'flappers'), 0.000331564986737383]\n",
      "That was Alice who kept may king murdering harm persisted cats harm Twenty flappers\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'save'), 0.000331564986737383]\n",
      "Winning match is:  [(u'was', u'Alice', u'who', u'save', u'fancy'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Alice', u'who', u'save', u'fancy', u'Heads'), 0.000331564986737383]\n",
      "Winning match is:  [(u'who', u'save', u'fancy', u'Heads', u')'), 0.000331564986737383]\n",
      "Winning match is:  [(u'save', u'fancy', u'Heads', u')', u'sorrow'), 0.000331564986737383]\n",
      "Winning match is:  [(u'fancy', u'Heads', u')', u'sorrow', u'.]'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Heads', u')', u'sorrow', u'.]', u'you'), 0.000331564986737383]\n",
      "Winning match is:  [(u')', u'sorrow', u'.]', u'you', u'explain'), 0.000331564986737383]\n",
      "Winning match is:  [(u'sorrow', u'.]', u'you', u'explain', u'the'), 0.000331564986737383]\n",
      "Winning match is:  [(u'.]', u'you', u'explain', u'the', u'All'), 0.000331564986737383]\n",
      "That was Alice who save fancy Heads ) sorrow .] you explain the All\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'finished'), 0.000331564986737383]\n",
      "Winning match is:  [(u'was', u'Alice', u'who', u'finished', u'Fish'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Alice', u'who', u'finished', u'Fish', u'not'), 0.000331564986737383]\n",
      "Winning match is:  [(u'who', u'finished', u'Fish', u'not', u'list'), 0.000331564986737383]\n",
      "Winning match is:  [(u'finished', u'Fish', u'not', u'list', u'Will'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Fish', u'not', u'list', u'Will', u'pence'), 0.000331564986737383]\n",
      "Winning match is:  [(u'not', u'list', u'Will', u'pence', u'shining'), 0.000331564986737383]\n",
      "Winning match is:  [(u'list', u'Will', u'pence', u'shining', u'grow'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Will', u'pence', u'shining', u'grow', u'patted'), 0.000331564986737383]\n",
      "Winning match is:  [(u'pence', u'shining', u'grow', u'patted', u'rush'), 0.000331564986737383]\n",
      "That was Alice who finished Fish not list Will pence shining grow patted rush\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'hair'), 0.000331564986737383]\n",
      "Winning match is:  [(u'was', u'Alice', u'who', u'hair', u'off'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Alice', u'who', u'hair', u'off', u'Longitude'), 0.000331564986737383]\n",
      "Winning match is:  [(u'who', u'hair', u'off', u'Longitude', u'shaped'), 0.000331564986737383]\n",
      "Winning match is:  [(u'hair', u'off', u'Longitude', u'shaped', u'fair'), 0.000331564986737383]\n",
      "Winning match is:  [(u'off', u'Longitude', u'shaped', u'fair', u'Stuff'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Longitude', u'shaped', u'fair', u'Stuff', u'frighten'), 0.000331564986737383]\n",
      "Winning match is:  [(u'shaped', u'fair', u'Stuff', u'frighten', u'Allow'), 0.000331564986737383]\n",
      "Winning match is:  [(u'fair', u'Stuff', u'frighten', u'Allow', u'Rule'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Stuff', u'frighten', u'Allow', u'Rule', u'riper'), 0.000331564986737383]\n",
      "That was Alice who hair off Longitude shaped fair Stuff frighten Allow Rule riper\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'trotting'), 0.000331564986737383]\n",
      "Winning match is:  [(u'was', u'Alice', u'who', u'trotting', u'spectacles'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Alice', u'who', u'trotting', u'spectacles', u'est'), 0.000331564986737383]\n",
      "Winning match is:  [(u'who', u'trotting', u'spectacles', u'est', u'HATED'), 0.000331564986737383]\n",
      "Winning match is:  [(u'trotting', u'spectacles', u'est', u'HATED', u'passion'), 0.000331564986737383]\n",
      "Winning match is:  [(u'spectacles', u'est', u'HATED', u'passion', u'somebody'), 0.000331564986737383]\n",
      "Winning match is:  [(u'est', u'HATED', u'passion', u'somebody', u'rats'), 0.000331564986737383]\n",
      "Winning match is:  [(u'HATED', u'passion', u'somebody', u'rats', u'part'), 0.000331564986737383]\n",
      "Winning match is:  [(u'passion', u'somebody', u'rats', u'part', u'All'), 0.000331564986737383]\n",
      "Winning match is:  [(u'somebody', u'rats', u'part', u'All', u'bound'), 0.000331564986737383]\n",
      "That was Alice who trotting spectacles est HATED passion somebody rats part All bound\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'MARMALADE'), 0.000331564986737383]\n",
      "Winning match is:  [(u'was', u'Alice', u'who', u'MARMALADE', u'Northumbria'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Alice', u'who', u'MARMALADE', u'Northumbria', u'feebly'), 0.000331564986737383]\n",
      "Winning match is:  [(u'who', u'MARMALADE', u'Northumbria', u'feebly', u'grins'), 0.000331564986737383]\n",
      "Winning match is:  [(u'MARMALADE', u'Northumbria', u'feebly', u'grins', u'land'), 0.000331564986737383]\n",
      "Winning match is:  [(u'Northumbria', u'feebly', u'grins', u'land', u'feather'), 0.000331564986737383]\n",
      "Winning match is:  [(u'feebly', u'grins', u'land', u'feather', u'wig'), 0.000331564986737383]\n",
      "Winning match is:  [(u'grins', u'land', u'feather', u'wig', u'settled'), 0.000331564986737383]\n",
      "Winning match is:  [(u'land', u'feather', u'wig', u'settled', u'life'), 0.000331564986737383]\n",
      "Winning match is:  [(u'feather', u'wig', u'settled', u'life', u'Ou'), 0.000331564986737383]\n",
      "That was Alice who MARMALADE Northumbria feebly grins land feather wig settled life Ou\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    print fm.predict_words(\"That was Alice who\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Let's try without smoothing\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 1.0]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 1.0]\n",
      "her great disappointment it was\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 1.0]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 1.0]\n",
      "her great disappointment it was\n",
      "2.93194945319e-05\n",
      "0.0\n",
      "\n",
      " Let's try WittenBell\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'singing'), 0.0003315649867373829]\n",
      "Winning match is:  [(u'great', u'disappointment', u'singing', u'everything'), 0.0003315649867373829]\n",
      "her great disappointment singing everything\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'escape'), 0.0003315649867373829]\n",
      "Winning match is:  [(u'great', u'disappointment', u'escape', u'show'), 0.0003315649867373829]\n",
      "her great disappointment escape show\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'daughter'), 0.0003315649867373829]\n",
      "Winning match is:  [(u'great', u'disappointment', u'daughter', u'hoarse'), 0.0003315649867373829]\n",
      "her great disappointment daughter hoarse\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'closed'), 0.0003315649867373829]\n",
      "Winning match is:  [(u'great', u'disappointment', u'closed', u']'), 0.0003315649867373829]\n",
      "her great disappointment closed ]\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'anywhere'), 0.0003315649867373829]\n",
      "Winning match is:  [(u'great', u'disappointment', u'anywhere', u'tidy'), 0.0003315649867373829]\n",
      "her great disappointment anywhere tidy\n",
      "1.53981183499e-05\n",
      "1.53981183499e-05\n",
      "\n",
      " Let's try Lidstone\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'introduce'), 0.00033134526176274774]\n",
      "Winning match is:  [(u'great', u'disappointment', u'introduce', u'maybe'), 0.00033156498673739146]\n",
      "her great disappointment introduce maybe\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'Be'), 0.00033134526176274774]\n",
      "Winning match is:  [(u'great', u'disappointment', u'Be', u'depends'), 0.00033156498673739146]\n",
      "her great disappointment Be depends\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'besides'), 0.00033134526176274774]\n",
      "Winning match is:  [(u'great', u'disappointment', u'besides', u'pace'), 0.00033156498673739146]\n",
      "her great disappointment besides pace\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'plates'), 0.00033134526176274774]\n",
      "Winning match is:  [(u'great', u'disappointment', u'plates', u'treading'), 0.00033156498673739146]\n",
      "her great disappointment plates treading\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'Catch'), 0.00033134526176274774]\n",
      "Winning match is:  [(u'great', u'disappointment', u'Catch', u'honest'), 0.00033156498673739146]\n",
      "her great disappointment Catch honest\n",
      "3.02877334679e-05\n",
      "1.0095911156e-05\n",
      "\n",
      " Let's try Laplace\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'hers'), 0.00033145508783558064]\n",
      "Winning match is:  [(u'great', u'disappointment', u'hers', u'tunnel'), 0.0003315649867373829]\n",
      "her great disappointment hers tunnel\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'enormous'), 0.00033145508783558064]\n",
      "Winning match is:  [(u'great', u'disappointment', u'enormous', u'shower'), 0.0003315649867373829]\n",
      "her great disappointment enormous shower\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'quarrelling'), 0.00033145508783558064]\n",
      "Winning match is:  [(u'great', u'disappointment', u'quarrelling', u'occasionally'), 0.0003315649867373829]\n",
      "her great disappointment quarrelling occasionally\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'everybody'), 0.00033145508783558064]\n",
      "Winning match is:  [(u'great', u'disappointment', u'everybody', u'picked'), 0.0003315649867373829]\n",
      "her great disappointment everybody picked\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'became'), 0.00033145508783558064]\n",
      "Winning match is:  [(u'great', u'disappointment', u'became', u'said'), 0.0003315649867373829]\n",
      "her great disappointment became said\n",
      "3.07962366999e-05\n",
      "1.53981183499e-05\n",
      "\n",
      " Let's try SimpleGoodTuring\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 0.999986994441382]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 0.999986994441382]\n",
      "her great disappointment it was\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 0.999986994441382]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 0.999986994441382]\n",
      "her great disappointment it was\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 0.999986994441382]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 0.999986994441382]\n",
      "her great disappointment it was\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 0.999986994441382]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 0.999986994441382]\n",
      "her great disappointment it was\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 0.999986994441382]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 0.999986994441382]\n",
      "her great disappointment it was\n",
      "2.38862690455e-06\n",
      "1.03037582927e-14\n"
     ]
    }
   ],
   "source": [
    "fm = NgramModel(4);\n",
    "fm.train(carroll);\n",
    "\n",
    "print \"\\n Let's try without smoothing\"\n",
    "for k in range(2):\n",
    "    print fm.predict_words(\"her great disappointment\", 2)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try WittenBell\"\n",
    "fm.smooth(\"WittenBellProbDist\", fm.frequencies, 2*fm.frequencies.B())\n",
    "for k in range(5):\n",
    "    print fm.predict_words(\"her great disappointment\", 2)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try Lidstone\"\n",
    "fm.smooth(\"LidstoneProbDist\", fm.frequencies, 0.5)\n",
    "for k in range(5):\n",
    "    print fm.predict_words(\"her great disappointment\", 2)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try Laplace\"\n",
    "fm.smooth(\"LaplaceProbDist\", fm.frequencies)\n",
    "for k in range(5):\n",
    "    print fm.predict_words(\"her great disappointment\", 2)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try SimpleGoodTuring\"\n",
    "fm.smooth(\"SimpleGoodTuringProbDist\", fm.frequencies, len(fm.unique_words) ** 4)\n",
    "for k in range(5):\n",
    "    print fm.predict_words(\"her great disappointment\", 2)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.02877334679e-05\n",
      "1.0095911156e-05\n"
     ]
    }
   ],
   "source": [
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3016"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fm.unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.932230385e-08"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.932230385e-05*0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
