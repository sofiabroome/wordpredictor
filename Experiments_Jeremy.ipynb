{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from models.ngram_model import NgramModel\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "carroll = gutenberg.words('carroll-alice.txt')\n",
    "s1 = gutenberg.words('shakespeare-caesar.txt');\n",
    "s2 = gutenberg.words('shakespeare-hamlet.txt');\n",
    "s3 = gutenberg.words('shakespeare-macbeth.txt');\n",
    "# print len(s1), len(s2), len(s3)\n",
    "# print len(carroll)\n",
    "# gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_corpora(corpora, query, n):\n",
    "    for k in range(2, 5, 1):\n",
    "        fm = NgramModel(k)\n",
    "        fm.train(corpora)\n",
    "        print \"Result for a\",(str(k)+\"-gram: \"),fm.predict_words(query, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a 2-gram:  Alice was looking for you only hear you fellows were all : ' t\n",
      "Result for a 3-gram:  Alice was looking for them , but in a whisper .) ' You '\n",
      "Result for a 4-gram:  Alice was looking for the fan and gloves , and was just going to\n"
     ]
    }
   ],
   "source": [
    "test_corpora(carroll, \"Alice was looking for\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  However , there is a whale - fleet of this , and the two\n",
      "Result for a  3-gram:  However , there is no place to live in the captain ' s a\n",
      "Result for a  4-gram:  However , there is no telling . But a day or two previous ,\n"
     ]
    }
   ],
   "source": [
    "test_corpora(melville, \"However , there is\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  I think that you must have been offered a whale , when the long\n",
      "Result for a  3-gram:  I think that you do yours in approved state stocks bringing in good time\n",
      "Result for a  4-gram:  I think that you really perceived drops of moisture in the spout - hole\n"
     ]
    }
   ],
   "source": [
    "test_corpora(melville, \"I think that you\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25833 37360 23140\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  You are in great Caesar , and for your Testie Humour ? And do you are at Philippi Bru . I know not Brutus , I am no man , and friendly Conference ,\n",
      "Result for a  3-gram:  You are in great Caesars eare , For if thou louest me , Ile ne ' re look ' d , And tell them , it is not the Face of men , and\n",
      "Result for a  4-gram:  You are in great danger , I recouer them . As proper men as euer trod vpon Neats Leather , haue gone vpon my handy - worke Fla . But wherefore did you so\n"
     ]
    }
   ],
   "source": [
    "test_corpora(s1, \"You are in great\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  This great buyer of the King . I could be so , That I am very potent poyson in this ; Addicted so ,\n",
      "Result for a  3-gram:  This great buyer of Land , And so am I ? Is it your owne necke downe Qu . Alas then , my Lord\n",
      "Result for a  4-gram:  This great buyer of Land , with his Statutes , his Recognizances , his Fines , and the trifling of his fauours , Hold\n"
     ]
    }
   ],
   "source": [
    "test_corpora(s2, \"This great buyer of\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for a  2-gram:  I am afraid they not be done to thine owne demerits , That most may you haue tied me , and trouble , And\n",
      "Result for a  3-gram:  I am afraid they haue more vices then it had before , to thinke what I doe , and the Ague eate them vp\n",
      "Result for a  4-gram:  I am afraid they haue awak ' d him well , He hath a Wisdome , that doth guide his Valour , To act\n"
     ]
    }
   ],
   "source": [
    "test_corpora(s3, \"I am afraid they\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIRST EXPERIMENTS : TUNING N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for a 2-gram: \n",
      "Alice was looking for she ' s the morning I ' You know .\n",
      "Alice was looking for Mabel ! Turn a stalk out , and she might\n",
      "Alice was looking for them off after all the Cat : she thought Alice\n",
      "Alice was looking for she picked up against the Mock Turtle yet .' '\n",
      "Alice was looking for I can find it , after her foot ! And\n",
      "\n",
      "\n",
      "Results for a 3-gram: \n",
      "Alice was looking for it ,' said Alice in a whisper , half to\n",
      "Alice was looking for the rest waited in silence . ' Well , I\n",
      "Alice was looking for it might end , you know .' ' Why ,\n",
      "Alice was looking for eggs , I can ' t have put it in\n",
      "Alice was looking for eggs , I know all the unjust things --' when\n",
      "\n",
      "\n",
      "Results for a 4-gram: \n",
      "Alice was looking for the fan and a pair of gloves and a fan\n",
      "Alice was looking for the fan and gloves , and , just as if\n",
      "Alice was looking for the fan and gloves -- that is , but I\n",
      "Alice was looking for the fan and the pair of white kid gloves and\n",
      "Alice was looking for the fan and the pair of white kid gloves in\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(2, 5, 1):\n",
    "    fm = NgramModel(k)\n",
    "    fm.train(carroll)\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm.predict_words(\"Alice was looking for\", 10)\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for a 2-gram: \n",
      "I am afraid they had Chestnuts in vnusuall Pleasure , Rosse . This deed\n",
      "I am afraid they liue a Truth , and Slippes of the Gin Son"
     ]
    }
   ],
   "source": [
    "for k in range(2, 5, 1):\n",
    "    fm = NgramModel(k)\n",
    "    fm.train(s3)\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm.predict_words(\"I am afraid they\", 10)\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOOTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no likely ngram with these last words. Try some smoothing methods.\n",
      "That was Alice who\n",
      "3016\n"
     ]
    }
   ],
   "source": [
    "fm = NgramModel(5);\n",
    "fm.train(carroll);\n",
    "print fm.predict_words(\"That was Alice who\", 5)\n",
    "print len(fm.unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'Hearts'), 0.000331564986737383]\n",
      "That was Alice who Hearts\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'where'), 0.000331564986737383]\n",
      "That was Alice who where\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'ignorant'), 0.000331564986737383]\n",
      "That was Alice who ignorant\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'truth'), 0.000331564986737383]\n",
      "That was Alice who truth\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'fix'), 0.000331564986737383]\n",
      "That was Alice who fix\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'settle'), 0.000331564986737383]\n",
      "That was Alice who settle\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'executioner'), 0.000331564986737383]\n",
      "That was Alice who executioner\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'Your'), 0.000331564986737383]\n",
      "That was Alice who Your\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'soup'), 0.000331564986737383]\n",
      "That was Alice who soup\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'lips'), 0.000331564986737383]\n",
      "That was Alice who lips\n"
     ]
    }
   ],
   "source": [
    "fm.smooth(\"LidstoneProbDist\", fm.frequencies, 0.5)\n",
    "for k in range(10):\n",
    "    print fm.predict_words(\"That was Alice who\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'fairy'), 0.00033156498673740165]\n",
      "That was Alice who fairy\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'Croquet'), 0.00033156498673740165]\n",
      "That was Alice who Croquet\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'accounts'), 0.00033156498673740165]\n",
      "That was Alice who accounts\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'parchment'), 0.00033156498673740165]\n",
      "That was Alice who parchment\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'skurried'), 0.00033156498673740165]\n",
      "That was Alice who skurried\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'considered'), 0.00033156498673740165]\n",
      "That was Alice who considered\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'unjust'), 0.00033156498673740165]\n",
      "That was Alice who unjust\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'opposite'), 0.00033156498673740165]\n",
      "That was Alice who opposite\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'smoke'), 0.00033156498673740165]\n",
      "That was Alice who smoke\n",
      "Winning match is:  [('That', 'was', 'Alice', 'who', u'Caterpillar'), 0.00033156498673740165]\n",
      "That was Alice who Caterpillar\n"
     ]
    }
   ],
   "source": [
    "fm.smooth(\"LaplaceProbDist\", fm.frequencies)\n",
    "for k in range(10):\n",
    "    print fm.predict_words(\"That was Alice who\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Let's try without smoothing\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 1.0]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 1.0]\n",
      "her great disappointment it was\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 1.0]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 1.0]\n",
      "her great disappointment it was\n",
      "2.93194945319e-05\n",
      "0.0\n",
      "\n",
      " Let's try WittenBell\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'singing'), 0.0003315649867373829]\n",
      "Winning match is:  [(u'great', u'disappointment', u'singing', u'everything'), 0.0003315649867373829]\n",
      "her great disappointment singing everything\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'escape'), 0.0003315649867373829]\n",
      "Winning match is:  [(u'great', u'disappointment', u'escape', u'show'), 0.0003315649867373829]\n",
      "her great disappointment escape show\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'daughter'), 0.0003315649867373829]\n",
      "Winning match is:  [(u'great', u'disappointment', u'daughter', u'hoarse'), 0.0003315649867373829]\n",
      "her great disappointment daughter hoarse\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'closed'), 0.0003315649867373829]\n",
      "Winning match is:  [(u'great', u'disappointment', u'closed', u']'), 0.0003315649867373829]\n",
      "her great disappointment closed ]\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'anywhere'), 0.0003315649867373829]\n",
      "Winning match is:  [(u'great', u'disappointment', u'anywhere', u'tidy'), 0.0003315649867373829]\n",
      "her great disappointment anywhere tidy\n",
      "1.53981183499e-05\n",
      "1.53981183499e-05\n",
      "\n",
      " Let's try Lidstone\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'introduce'), 0.00033134526176274774]\n",
      "Winning match is:  [(u'great', u'disappointment', u'introduce', u'maybe'), 0.00033156498673739146]\n",
      "her great disappointment introduce maybe\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'Be'), 0.00033134526176274774]\n",
      "Winning match is:  [(u'great', u'disappointment', u'Be', u'depends'), 0.00033156498673739146]\n",
      "her great disappointment Be depends\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'besides'), 0.00033134526176274774]\n",
      "Winning match is:  [(u'great', u'disappointment', u'besides', u'pace'), 0.00033156498673739146]\n",
      "her great disappointment besides pace\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'plates'), 0.00033134526176274774]\n",
      "Winning match is:  [(u'great', u'disappointment', u'plates', u'treading'), 0.00033156498673739146]\n",
      "her great disappointment plates treading\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'Catch'), 0.00033134526176274774]\n",
      "Winning match is:  [(u'great', u'disappointment', u'Catch', u'honest'), 0.00033156498673739146]\n",
      "her great disappointment Catch honest\n",
      "3.02877334679e-05\n",
      "1.0095911156e-05\n",
      "\n",
      " Let's try Laplace\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'hers'), 0.00033145508783558064]\n",
      "Winning match is:  [(u'great', u'disappointment', u'hers', u'tunnel'), 0.0003315649867373829]\n",
      "her great disappointment hers tunnel\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'enormous'), 0.00033145508783558064]\n",
      "Winning match is:  [(u'great', u'disappointment', u'enormous', u'shower'), 0.0003315649867373829]\n",
      "her great disappointment enormous shower\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'quarrelling'), 0.00033145508783558064]\n",
      "Winning match is:  [(u'great', u'disappointment', u'quarrelling', u'occasionally'), 0.0003315649867373829]\n",
      "her great disappointment quarrelling occasionally\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'everybody'), 0.00033145508783558064]\n",
      "Winning match is:  [(u'great', u'disappointment', u'everybody', u'picked'), 0.0003315649867373829]\n",
      "her great disappointment everybody picked\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'became'), 0.00033145508783558064]\n",
      "Winning match is:  [(u'great', u'disappointment', u'became', u'said'), 0.0003315649867373829]\n",
      "her great disappointment became said\n",
      "3.07962366999e-05\n",
      "1.53981183499e-05\n",
      "\n",
      " Let's try SimpleGoodTuring\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 0.999986994441382]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 0.999986994441382]\n",
      "her great disappointment it was\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 0.999986994441382]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 0.999986994441382]\n",
      "her great disappointment it was\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 0.999986994441382]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 0.999986994441382]\n",
      "her great disappointment it was\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 0.999986994441382]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 0.999986994441382]\n",
      "her great disappointment it was\n",
      "Winning match is:  [('her', 'great', 'disappointment', u'it'), 0.999986994441382]\n",
      "Winning match is:  [(u'great', u'disappointment', u'it', u'was'), 0.999986994441382]\n",
      "her great disappointment it was\n",
      "2.38862690455e-06\n",
      "1.03037582927e-14\n"
     ]
    }
   ],
   "source": [
    "fm = NgramModel(4);\n",
    "fm.train(carroll);\n",
    "\n",
    "print \"\\n Let's try without smoothing\"\n",
    "for k in range(2):\n",
    "    print fm.predict_words(\"her great disappointment\", 2)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try WittenBell\"\n",
    "fm.smooth(\"WittenBellProbDist\", fm.frequencies, 2*fm.frequencies.B())\n",
    "for k in range(5):\n",
    "    print fm.predict_words(\"her great disappointment\", 2)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try Lidstone\"\n",
    "fm.smooth(\"LidstoneProbDist\", fm.frequencies, 0.5)\n",
    "for k in range(5):\n",
    "    print fm.predict_words(\"her great disappointment\", 2)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try Laplace\"\n",
    "fm.smooth(\"LaplaceProbDist\", fm.frequencies)\n",
    "for k in range(5):\n",
    "    print fm.predict_words(\"her great disappointment\", 2)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try SimpleGoodTuring\"\n",
    "fm.smooth(\"SimpleGoodTuringProbDist\", fm.frequencies, len(fm.unique_words) ** 4)\n",
    "for k in range(5):\n",
    "    print fm.predict_words(\"her great disappointment\", 2)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Let's try without smoothing\n",
      "2.93194945319e-05\n",
      "0.0\n",
      "\n",
      " Let's try WittenBell\n",
      "1.53981183499e-05\n",
      "1.53981183499e-05\n",
      "\n",
      " Let's try Lidstone\n",
      "3.02877334679e-05\n",
      "1.0095911156e-05\n",
      "\n",
      " Let's try Laplace\n",
      "3.07962366999e-05\n",
      "1.53981183499e-05\n",
      "\n",
      " Let's try SimpleGoodTuring\n",
      "2.38862690455e-06\n",
      "1.03037582927e-14\n"
     ]
    }
   ],
   "source": [
    "fm = NgramModel(4);\n",
    "fm.train(carroll);\n",
    "\n",
    "print \"\\n Let's try without smoothing\"\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try WittenBell\"\n",
    "fm.smooth(\"WittenBellProbDist\", fm.frequencies, 2*fm.frequencies.B())\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try Lidstone\"\n",
    "fm.smooth(\"LidstoneProbDist\", fm.frequencies, 0.5)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "print \"\\n Let's try Laplace\"\n",
    "fm.smooth(\"LaplaceProbDist\", fm.frequencies)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))\n",
    "\n",
    "\n",
    "print \"\\n Let's try SimpleGoodTuring\"\n",
    "fm.smooth(\"SimpleGoodTuringProbDist\", fm.frequencies, len(fm.unique_words) ** 4)\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'it'))\n",
    "print fm.probs_ng.prob(('her', 'great', 'disappointment', 'depends'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3016 unique words in this dataset.\n",
      "Frequency of (she, was): 49\n",
      "Frequency of (she, is): 3\n",
      "Frequency of (she, blue): 0 \n",
      "\n",
      "Prob of (she, is): 8.79533261016e-05\n",
      "Prob of (she, was): 0.00143657099299\n",
      "Prob of (she, blue): 0.0\n",
      "Prob ratio was/is: 16.3333333333\n",
      "\n",
      "SimpleGoodTuring\n",
      "\n",
      "Prob of (she, is): 6.0723297438e-05\n",
      "Prob of (she, was): 0.00139591586689\n",
      "Prob of (she, blue): 3.70129741617e-08\n",
      "Prob ratio was/is: 22.9881433615\n",
      "Prob ratio was/blue: 37714.2312527\n",
      "\n",
      "WittenBell\n",
      "\n",
      "Prob of (she, is): 6.02494326512e-05\n",
      "Prob of (she, was): 0.000984074066636\n",
      "Prob of (she, blue): 3.46876864035e-08\n",
      "Prob ratio was/is: 16.3333333333\n",
      "Prob ratio was/blue: 28369.5503698\n",
      "\n",
      "LidstoneProbDist with parameter 0.5\n",
      "\n",
      "Prob of (she, is): 8.3430669114e-05\n",
      "Prob of (she, was): 0.00117994803461\n",
      "Prob of (she, blue): 1.19186670163e-05\n",
      "Prob ratio was/is: 14.1428571429\n",
      "Prob ratio was/blue: 99.0\n",
      "\n",
      "LidstoneProbDist with parameter 1\n",
      "\n",
      "Prob of (she, is): 8.03325768682e-05\n",
      "Prob of (she, was): 0.00100415721085\n",
      "Prob of (she, blue): 2.00831442171e-05\n",
      "Prob ratio was/is: 12.5\n",
      "Prob ratio was/blue: 50.0\n",
      "\n",
      "LaplaceProbDist\n",
      "\n",
      "Frequency of (she, was): 49\n",
      "Frequency of (she, is): 3\n",
      "Frequency of (she, blue): 0 \n",
      "\n",
      "Prob of (she, is): 8.03325768682e-05\n",
      "Prob of (she, was): 0.00100415721085\n",
      "Prob of (she, blue): 2.00831442171e-05\n",
      "Prob ratio was/is: 12.5\n",
      "Prob ratio was/blue: 50.0\n"
     ]
    }
   ],
   "source": [
    "fm = NgramModel(2);\n",
    "fm.train(carroll);\n",
    "print \"There are\", len(fm.unique_words), \"unique words in this dataset.\"\n",
    "\n",
    "print \"Frequency of (she, was):\", fm.frequencies[('she','was')]\n",
    "print \"Frequency of (she, is):\", fm.frequencies[('she','is')]\n",
    "print \"Frequency of (she, blue):\", fm.frequencies[('she','blue')], \"\\n\"\n",
    "print \"Prob of (she, is):\", fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob of (she, was):\", fm.probs_ng.prob(('she', 'was'))\n",
    "print \"Prob of (she, blue):\", fm.probs_ng.prob(('she', 'blue'))\n",
    "print \"Prob ratio was/is:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'is'))\n",
    "\n",
    "\n",
    "# Gives a probability to a n-grams counted n-times given the probabilities of n-gram counted n+1-times.\n",
    "\n",
    "print \"\\nSimpleGoodTuring\\n\"\n",
    "fm.smooth(\"SimpleGoodTuringProbDist\", fm.frequencies, len(fm.unique_words) ** 2)\n",
    "print \"Prob of (she, is):\", fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob of (she, was):\", fm.probs_ng.prob(('she', 'was'))\n",
    "print \"Prob of (she, blue):\", fm.probs_ng.prob(('she', 'blue'))\n",
    "print \"Prob ratio was/is:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob ratio was/blue:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'blue'))\n",
    "\n",
    "\n",
    "# The probability mass of unseen events equals the probability mass of events that occured once in the corpora\n",
    "\n",
    "print \"\\nWittenBell\\n\"\n",
    "fm.smooth(\"WittenBellProbDist\", fm.frequencies, len(fm.unique_words) ** 2)\n",
    "print \"Prob of (she, is):\", fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob of (she, was):\", fm.probs_ng.prob(('she', 'was'))\n",
    "print \"Prob of (she, blue):\", fm.probs_ng.prob(('she', 'blue'))\n",
    "print \"Prob ratio was/is:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob ratio was/blue:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'blue'))\n",
    "\n",
    "\n",
    "# Adds 0.5 to each frequency and then computes MLE\n",
    "\n",
    "print \"\\nLidstoneProbDist with parameter 0.5\\n\"\n",
    "fm.smooth(\"LidstoneProbDist\", fm.frequencies, 0.5)\n",
    "print \"Prob of (she, is):\", fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob of (she, was):\", fm.probs_ng.prob(('she', 'was'))\n",
    "print \"Prob of (she, blue):\", fm.probs_ng.prob(('she', 'blue'))\n",
    "print \"Prob ratio was/is:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob ratio was/blue:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'blue'))\n",
    "\n",
    "\n",
    "\n",
    "# Lidstone with parameter 1 should be the same as Laplace since it just adds one to each frequency and does MLE.\n",
    "\n",
    "print \"\\nLidstoneProbDist with parameter 1\\n\"\n",
    "fm.smooth(\"LidstoneProbDist\", fm.frequencies, 1)\n",
    "print \"Prob of (she, is):\", fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob of (she, was):\", fm.probs_ng.prob(('she', 'was'))\n",
    "print \"Prob of (she, blue):\", fm.probs_ng.prob(('she', 'blue'))\n",
    "print \"Prob ratio was/is:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob ratio was/blue:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'blue'))\n",
    "\n",
    "print \"\\nLaplaceProbDist\\n\"\n",
    "fm.smooth(\"LaplaceProbDist\", fm.frequencies)\n",
    "print \"Prob of (she, is):\", fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob of (she, was):\", fm.probs_ng.prob(('she', 'was'))\n",
    "print \"Prob of (she, blue):\", fm.probs_ng.prob(('she', 'blue'))\n",
    "print \"Prob ratio was/is:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'is'))\n",
    "print \"Prob ratio was/blue:\", fm.probs_ng.prob(('she', 'was')) / fm.probs_ng.prob(('she', 'blue'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
