{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments for n-grams without smoothing or grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'austen-emma.txt',\n",
       " u'austen-persuasion.txt',\n",
       " u'austen-sense.txt',\n",
       " u'bible-kjv.txt',\n",
       " u'blake-poems.txt',\n",
       " u'bryant-stories.txt',\n",
       " u'burgess-busterbrown.txt',\n",
       " u'carroll-alice.txt',\n",
       " u'chesterton-ball.txt',\n",
       " u'chesterton-brown.txt',\n",
       " u'chesterton-thursday.txt',\n",
       " u'edgeworth-parents.txt',\n",
       " u'melville-moby_dick.txt',\n",
       " u'milton-paradise.txt',\n",
       " u'shakespeare-caesar.txt',\n",
       " u'shakespeare-hamlet.txt',\n",
       " u'shakespeare-macbeth.txt',\n",
       " u'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.bigram_model import BigramModel\n",
    "from models.trigram_model import TrigramModel\n",
    "from models.ngram_model import NgramModel\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_corpora(corpora, query, n): # method to initiate an n-gram model and train it with\n",
    "                                     # a corpora and send in a query to the model's\n",
    "                                     # predict_words method\n",
    "    for k in range(2, 5, 1):\n",
    "        fm = NgramModel(k)\n",
    "        fm.train(corpora)\n",
    "        print \"Result for a\",(str(k)+\"-gram: \"),fm.predict_words(query, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010654 154883 8354\n"
     ]
    }
   ],
   "source": [
    "t1 = gutenberg.words('bible-kjv.txt');\n",
    "t2 = gutenberg.words('whitman-leaves.txt');\n",
    "t3 = gutenberg.words('blake-poems.txt');\n",
    "print len(t1), len(t2), len(t3)  #checking lengths of the above texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biblePart = t1[:100000]\n",
    "len(biblePart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with first 100 000 words of the bible\n",
      "Results for a 2-gram: \n",
      "And they were both naked unto Pharaoh ' s milk , and shut him .\n",
      "And they were both naked ? 26 And Miriam the flesh from thence did Sarah\n",
      "And they were both naked ? what hast done in the best of the north\n",
      "And they were both naked , I have established by my master saw that he\n",
      "And they were both naked ; and daubed it without blemish unto him : 13\n",
      "\n",
      "\n",
      "\n",
      "Testing with first 100 000 words of the bible\n",
      "Results for a 3-gram: \n",
      "And they were both naked , the people , and Calneh , in the coupling\n",
      "And they were both naked , the face of the burnt offering , even the\n",
      "And they were both naked , the children of Israel , and the sheep .\n",
      "And they were both naked , the camels had done to him as before .\n",
      "And they were both naked , the God of thy servants it be for a\n",
      "\n",
      "\n",
      "\n",
      "Testing with first 100 000 words of the bible\n",
      "Results for a 4-gram: \n",
      "And they were both naked , the man that brought us up out of the\n",
      "And they were both naked , the man is become as one of the Hebrews\n",
      "And they were both naked , the man is become as one of them opened\n",
      "And they were both naked , the man that brought us up out of that\n",
      "And they were both naked , the man and his household came with Jacob .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The entire bible is too long, we take out around a tenth of it.\n",
    "\n",
    "biblePart = t1[:100000]\n",
    "\n",
    "for k in range(2, 5, 1):\n",
    "    fm1 = NgramModel(k)\n",
    "    fm1.train(biblePart)\n",
    "    print \"Testing with first 100 000 words of the bible\"\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm1.predict_words(\"And they were both naked\", 10)\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with the poetry collection Leaves of Grass, medium large (154883 words)\n",
      "Results for a 2-gram: \n",
      "The delicious singing of the mother ' d ship - clad soldiers of ooze and what\n",
      "The delicious singing of the mother ' d eve delicious word , Elements merge with the\n",
      "The delicious singing of the mother ' d back on the midst of Nature your tongue\n",
      "The delicious singing of the mother kisses of the clasp me shall cover ' s funeral\n",
      "The delicious singing of the mother told - lung ' d every blow through the same\n",
      "\n",
      "\n",
      "\n",
      "Testing with the poetry collection Leaves of Grass, medium large (154883 words)\n",
      "Results for a 3-gram: \n",
      "The delicious singing of the mother to part , and the climbing sap , Arms and\n",
      "The delicious singing of the mother sleeps with at night , The singers of old or\n",
      "The delicious singing of the mother misused by her children , resolute , under the sun\n",
      "The delicious singing of the mother never turning her vigilant eyes ,) Calmly a lady '\n",
      "The delicious singing of the mother of many nations , the shelves are crowded with perfumes\n",
      "\n",
      "\n",
      "\n",
      "Testing with the poetry collection Leaves of Grass, medium large (154883 words)\n",
      "Results for a 4-gram: \n",
      "The delicious singing of the mother shines on the white wrist of the daughter , The\n",
      "The delicious singing of the mother , the Mississippi flows , Of mighty inland cities yet\n",
      "The delicious singing of the mother of many children , These clamors wild to a race\n",
      "The delicious singing of the mother , or of me ; Of their languages , governments\n",
      "The delicious singing of the mother shines on the white wrist of the daughter , The\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(2, 5, 1):\n",
    "    fm2 = NgramModel(k)\n",
    "    fm2.train(t2)\n",
    "    print \"Testing with the poetry collection Leaves of Grass, medium large (154883 words)\"\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm2.predict_words(\"The delicious singing of the mother\", 10)\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with the poetry collection Leaves of Grass, medium large (154883 words)\n",
      "Results for a 2-gram: \n",
      "Sing on there in the swamp - congratulatory signs and dead . I shall never refuses\n",
      "Sing on there in the swamp in songs , English war , Sunlight by the Cascade\n",
      "Sing on there in the swamp - dug in disgrace to give an open air I\n",
      "Sing on there in the swamp , busier sphere more in granite walls of the West\n",
      "Sing on there in the swamp in vain the country ; You past .) Now I\n",
      "\n",
      "\n",
      "\n",
      "Testing with the poetry collection Leaves of Grass, medium large (154883 words)\n",
      "Results for a 3-gram: \n",
      "Sing on there in the swamp in the houses are alive with people , I pause\n",
      "Sing on there in the swamp in secluded recesses , From the head of the real\n",
      "Sing on there in the swamp - cedars , with muttering thunder and lambent eyes watch\n",
      "Sing on there in the swamp in the ranks marching , on I go , I\n",
      "Sing on there in the swamp - perfume , with brow elate and governing hand .\n",
      "\n",
      "\n",
      "\n",
      "Testing with the poetry collection Leaves of Grass, medium large (154883 words)\n",
      "Results for a 4-gram: \n",
      "Sing on there in the swamp , O singer bashful and tender , I hear in\n",
      "Sing on there in the swamp , O singer bashful and tender , I hear the\n",
      "Sing on there in the swamp , O singer bashful and tender , I hear the\n",
      "Sing on there in the swamp , O singer bashful and tender , I hear in\n",
      "Sing on there in the swamp , O singer bashful and tender , I hear the\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(2, 5, 1):\n",
    "    fm2 = NgramModel(k)\n",
    "    fm2.train(t2)\n",
    "    print \"Testing with the poetry collection Leaves of Grass, medium large (154883 words)\"\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm2.predict_words(\"Sing on there in the swamp\", 10)\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with Blake poems, small corpus (8354 words)\n",
      "Results for a 2-gram: \n",
      "Infant smiles are his own . Gone was thy Maker lay . Pretty joy to\n",
      "Infant smiles are his own destruction ? Can delight . Folly is dwelling too ?\n",
      "Infant smiles are his own smiles on my foe outstretched beneath the skies ; And\n",
      "Infant smiles are his own grave plot she in darkness plough ? Can a threat\n",
      "Infant smiles are his own destruction ? When we rose to tenfold life , merrily\n",
      "\n",
      "\n",
      "\n",
      "Testing with Blake poems, small corpus (8354 words)\n",
      "Results for a 3-gram: \n",
      "Infant smiles are his own smiles ; Heaven and earth to peace beguiles . DIVINE\n",
      "Infant smiles are his own smiles ; Heaven and earth to peace beguiles . DIVINE\n",
      "Infant smiles are his own smiles ; Heaven and earth to peace beguiles . DIVINE\n",
      "Infant smiles are his own smiles ; Heaven and earth to peace , and fled\n",
      "Infant smiles are his own smiles ; Heaven and earth to peace beguiles . DIVINE\n",
      "\n",
      "\n",
      "\n",
      "Testing with Blake poems, small corpus (8354 words)\n",
      "Results for a 4-gram: \n",
      "Infant smiles are his own smiles ; Heaven and earth to peace beguiles . DIVINE\n",
      "Infant smiles are his own smiles ; Heaven and earth to peace beguiles . DIVINE\n",
      "Infant smiles are his own smiles ; Heaven and earth to peace beguiles . DIVINE\n",
      "Infant smiles are his own smiles ; Heaven and earth to peace beguiles . DIVINE\n",
      "Infant smiles are his own smiles ; Heaven and earth to peace beguiles . DIVINE\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(2, 5, 1):\n",
    "    fm3 = NgramModel(k)\n",
    "    fm3.train(t3)\n",
    "    print \"Testing with Blake poems, small corpus (8354 words)\"\n",
    "    print \"Results for a\",(str(k)+\"-gram: \")\n",
    "    for k in range(5):\n",
    "        print fm3.predict_words(\"Infant smiles are his own\", 10)\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
