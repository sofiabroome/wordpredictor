{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once', 'upon', 'time', 'there', 'was', 'a', 'hippo', 'named', 'Alfred', '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.tokenize.word_tokenize(\"Once upon time there was a hippo named Alfred.\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Once', 'RB'),\n",
       " ('upon', 'IN'),\n",
       " ('time', 'NN'),\n",
       " ('there', 'EX'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('hippo', 'NN'),\n",
       " ('named', 'VBN'),\n",
       " ('Alfred', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hey', 'PRP'),\n",
       " (',', ','),\n",
       " ('can', 'MD'),\n",
       " ('I', 'PRP'),\n",
       " ('have', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('can', 'MD'),\n",
       " ('of', 'IN'),\n",
       " ('olives', 'NNS'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagger gets confused\n",
    "text = nltk.tokenize.word_tokenize(\"Hey, can I have that can of olives?\")\n",
    "#text = nltk.tokenize.word_tokenize(\"Can I have that can of olives?\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can: 94\n",
      "could: 87\n",
      "may: 93\n",
      "might: 38\n",
      "must: 53\n",
      "will: 389\n",
      "butter: 2\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "news_text = brown.words(categories='news')\n",
    "fdit = nltk.FreqDist(w.lower() for w in news_text)\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will', 'butter']\n",
    "for m in modals:\n",
    "    print m + ':', fdit[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Once', 'upon'),\n",
       " ('upon', 'a'),\n",
       " ('a', 'time'),\n",
       " ('time', 'there'),\n",
       " ('there', 'was'),\n",
       " ('was', 'a'),\n",
       " ('a', 'hippo'),\n",
       " ('hippo', 'named'),\n",
       " ('named', 'alfed')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Once upon a time there was a hippo named alfed\".split()\n",
    "list(nltk.bigrams(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some stuff from MAS and the nltk intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'BROWN CORPUS\\n\\nA Standard Corpus of Present-Day Edited American\\nEnglish, for use with Digital Computers.\\n\\nby W. N. Francis and H. Kucera (1964)\\nDepartment of Linguistics, Brown University\\nProvidence, Rhode Island, USA\\n\\nRevised 1971, Revised and Amplified 1979\\n\\nhttp://www.hit.uib.no/icame/brown/bcm.html\\n\\nDistributed with the permission of the copyright holder,\\nredistribution permitted.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.readme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'[', u'Moby', u'Dick', u'by', u'Herman', u'Melville', ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()\n",
    "words = gutenberg.words('melville-moby_dick.txt')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sperm Whale; Moby Dick; White Whale; old man; Captain Ahab; sperm\n",
      "whale; Right Whale; Captain Peleg; New Bedford; Cape Horn; cried Ahab;\n",
      "years ago; lower jaw; never mind; Father Mapple; cried Stubb; chief\n",
      "mate; white whale; ivory leg; one hand\n"
     ]
    }
   ],
   "source": [
    "mobydick = nltk.Text(words)\n",
    "mobydick.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqs = mobydick.vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = nltk.MLEProbDist(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003473673313677301"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.prob('whale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.prob('vanillafrog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs_d = nltk.WittenBellProbDist(freqs, freqs.B()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WittenBellProbDist based on 260819 samples>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06895579290059115"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this made up word should have the same prob as words with word count 1 in the corpus\n",
    "probs_d.prob('vanillafrog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try to make a bigram distr and use it to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mobydick_bg = nltk.bigrams(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mobydick_bg_fr = nltk.FreqDist(mobydick_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for k, v in mobydick_bg_fr.items():\n",
    "#     print k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobydick_bg_fr[(u'white', u'whale')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs_bg = nltk.MLEProbDist(mobydick_bg_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011885682736620939"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_bg.prob((u'white', u'whale'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"I would like to buy one can of white\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = []\n",
    "for bigram in nltk.bigrams(words):\n",
    "    if bigram[0] == unicode(query[-1]):\n",
    "        #print bigram, probs_bg.prob(bigram)\n",
    "        matches.append((bigram, probs_bg.prob(bigram)))  \n",
    "        #WHY does the same bigram (white, whale) appear svrl times, something is strange\n",
    "        #ed: no makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches.sort(key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((u'white', u'whale'), 0.00011885682736620939)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely query: \n",
      "I would like to buy one can of white whale\n"
     ]
    }
   ],
   "source": [
    "print \"Most likely query: \"\n",
    "print \" \".join(query) + \" \" + matches[-1][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### repeat the same step with a WittenBell distribution instead and try some other 'queries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  try and do the same as above with custom rap corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a quick and crude parsing, full of garbage tokens like urls and stuff.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open('ohhla.csv')\n",
    "freader = csv.reader(f)\n",
    "s = str()\n",
    "\n",
    "for ix, song in enumerate(freader):\n",
    "    if ix == 0: continue\n",
    "    s += ' '.join(song)\n",
    "    \n",
    "raptext = nltk.word_tokenize(s)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rapcorpus = nltk.Text(raptext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rap_bgf = nltk.FreqDist(nltk.bigrams(rapcorpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rap_bpr = nltk.WittenBellProbDist(rap_bgf, rap_bgf.B() + 1) #why B+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_bgf[('a', 'war')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00016570465906266398"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_bpr.prob((('a', 'war')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"I would like a\".split()\n",
    "matches = []\n",
    "for bigram in nltk.bigrams(rapcorpus):\n",
    "    if bigram[0] == unicode(query[-1]):\n",
    "#         print bigram, probs_bg.prob(bigram)\n",
    "        matches.append((bigram, rap_bpr.prob(bigram)))  \n",
    "\n",
    "matches.sort(key=lambda x: x[1])\n",
    "matches = sorted(set(matches), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely query: \n",
      "I would like a\n",
      "1 : nigga\n",
      "2 : soldier\n",
      "3 : war\n",
      "4 : little\n",
      "5 : million\n"
     ]
    }
   ],
   "source": [
    "print \"Most likely query: \"\n",
    "print ' '.join(query)\n",
    "n = 1\n",
    "for match in matches[:-6:-1]:\n",
    "    print n ,':', match[0][1]\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### try with a trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rap_tgf = nltk.FreqDist(nltk.trigrams(rapcorpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_tgf[('like', 'a', 'million')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rap_tpr = nltk.WittenBellProbDist(rap_tgf, rap_tgf.B() + 1) #why B+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.427243379693682e-05"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_tpr.prob(('like', 'a', 'million'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rap_tprML = nltk.MLEProbDist(rap_tgf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strange:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4579965533144008"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_tpr.prob(('like', 'a', 'millionZZZ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_tprML.prob(('like', 'a', 'millionZZZ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('like', 'a', 'nine') 0.0\n",
      "('like', 'a', 'ref') 0.0\n",
      "('like', 'a', 'Tec..') 0.0\n",
      "('like', 'a', 'three') 0.0\n",
      "('like', 'a', 'fiend') 0.0\n",
      "('like', 'a', 'well-trained') 0.0\n",
      "('like', 'a', 'pair') 0.0\n",
      "('like', 'a', 'Predator') 0.0\n",
      "('like', 'a', 'willow') 0.0\n",
      "('like', 'a', 'Yokohama') 0.0\n",
      "('like', 'a', 'moped') 0.0\n",
      "('like', 'a', 'twenty') 0.0\n",
      "('like', 'a', 'crab') 0.0\n",
      "('like', 'a', '75') 0.0\n",
      "('like', 'a', 'window') 0.0\n",
      "('like', 'a', 'strainer') 0.0\n",
      "('like', 'a', 'Kirby') 0.0\n",
      "('like', 'a', 'rattle') 0.0\n",
      "('like', 'a', 'million') 0.0\n",
      "('like', 'a', 'cut') 0.0\n",
      "('like', 'a', 'live') 0.0\n"
     ]
    }
   ],
   "source": [
    "query = \"I would like a\".split()\n",
    "matches = []\n",
    "for trigram in nltk.trigrams(rapcorpus):\n",
    "    if trigram[0] == unicode(query[-2]) and trigram[1] == unicode(query[-1]):\n",
    "        print trigram, probs_bg.prob(bigram)\n",
    "        matches.append((trigram, rap_tpr.prob(trigram)))  \n",
    "\n",
    "matches = sorted(set(matches), key=lambda x: x[1])\n",
    "\n",
    "# print \"Most likely query: \"\n",
    "# print ' '.join(query)\n",
    "# n = 1\n",
    "# for match in matches[:-6:-1]:\n",
    "#     print n ,':', match[0][1]\n",
    "#     n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?nltk.NgramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
